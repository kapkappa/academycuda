# Отчет по второму заданию
## Выбор grid|block архитектуры
Изначальная идея - использовать двумерный грид.
Однако, столкнулся с проблемой - если использовать block размера 32х32, а не 1х1, не получилось определить, попадает нить в нужный диапазон индексов, или нет (собственно с определением диапазона проблема).
Кроме того, если делать "влоб", гаранитрован неравномерный доступ к памяти к одному из массивов. Возможно, использование shared memory тут должно помочь (например, разделив матрицы на блоки, выделяя их отдельно в памяти), вкупе с более сложной обработкой индексов.

## Оценка результатов

1. size = 50
> Max memory: 1Mb

> Cpu time is: 1.90735e-06

> Gpu time is: 3.9936e-02
2. size = 100
> Max memory: 4Mb

> Cpu time is: 9.05991e-06

> Gpu time is: 4.2176e-02
3. size = 200
> Max memory: 4Mb

> Cpu time is: 5.10216e-05

> Gpu time is: 5.2672e-02
4. size = 500
> Max memory: 10Mb

> Cpu time: 3.65019e-04

> Gpu time is: 4.6752e-02
5. size = 1000
> Max memory: 28Mb

> Cpu time is: 1.43194e-03

> Gpu time is: 1.23328e-01
6. size = 2000
> Max memory: 89Mb

> Cpu time is: 8.09288e-03

> Gpu time is: 3.4144e-01
7. size = 5000
> Max memory: 400Mb

> Cpu time is: 5.98889e-01

> Gpu time is: 1.54275e+00
8. size = 10000
> Max memory: 1544Mb

> Cpu time is: 3.94869e+00

> Gpu time is: 9.71341e+00
9. size = 20000
> Max memory: 6132Mb

> Cpu time is: 1.76157e+01

> Gpu time is: 8.85659e+01

Из результатов видно, что не оптимизированный прямой алгоритм транспонирования, выполняемый на GPU, на не самых больших матрицах - на порядки менее эффективен, чем на CPU.
Однако, при этом, при увеличении размера матрицы, (до определенного момента), алгоритм на GPU масштабируется, и меньше проигрывает CPU версиии (не на порядки, а на 0-1 порядок).
